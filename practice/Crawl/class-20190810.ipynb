{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 : 取得隱藏變數 ok !!!\n",
      "Step 1 : 登入 ok !!!\n",
      "Step 2 : 文章列表 ok !!!\n",
      "[綜合討論]死靈法師要出了嗎?\n",
      "================================================================================\n",
      "********************************************************************************\n",
      "********************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-111-14886afc2889>\", line 150, in crawlArticleDetail\n",
      "    respAuthor = getAuthor(table)\n",
      "  File \"<ipython-input-111-14886afc2889>\", line 11, in getAuthor\n",
      "    author_post_cnt     = tdTag.select(\"dl.pil dd\")[0].text\n",
      "IndexError: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "********************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-111-14886afc2889>\", line 150, in crawlArticleDetail\n",
      "    respAuthor = getAuthor(table)\n",
      "  File \"<ipython-input-111-14886afc2889>\", line 11, in getAuthor\n",
      "    author_post_cnt     = tdTag.select(\"dl.pil dd\")[0].text\n",
      "IndexError: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[綜合討論]我的第一貼~算人品啦\n",
      "================================================================================\n",
      "[玩家互動]一顆頭的寵物:惡靈火顱\n",
      "================================================================================\n",
      "[玩家互動]炫耀文囉 因為太開心了 \n",
      "================================================================================\n",
      "[綜合討論]賽季18會不少傳奇會增加特效, 大家要回鍋嗎?\n",
      "================================================================================\n",
      "[綜合討論]暗黑破壞神快要被放棄了嗎?\n",
      "================================================================================\n",
      "[綜合討論]死靈法師技能試玩效果動畫分享 \n",
      "================================================================================\n",
      "[綜合討論]聖教軍推薦玩法?\n",
      "================================================================================\n",
      "Step 3 : 抓取文章內容 ok !!!\n",
      "Step 4 : 存成 excel ok !!!\n"
     ]
    }
   ],
   "source": [
    "# ##package\n",
    "\n",
    "import requests\n",
    "import traceback\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "\n",
    "### function\n",
    "\n",
    "def getAuthor(table):\n",
    "    authorEle   = mainTable.select(\"tr\")[0].select(\"td\")[0]\n",
    "    author_name = authorEle.select(\"div.authi a\")[0].text\n",
    "    tdTag       = table.select(\"tr\")[0].select(\"td\")[0]\n",
    "    \n",
    "    author_post_cnt     = tdTag.select(\"dl.pil dd\")[0].text\n",
    "    author_score        = tdTag.select(\"dl.pil dd\")[1].text.replace(\" 點\",\"\")\n",
    "    author_diving_value = tdTag.select(\"dl.pil dd\")[2].text.replace(\" 米\",\"\")\n",
    "    \n",
    "    return {\n",
    "        \"author_name\" : author_name,\n",
    "        \"author_post_cnt\"     : int(author_post_cnt),\n",
    "        \"author_score\"        : int(author_score),\n",
    "        \"author_diving_value\" : int(author_diving_value)\n",
    "    }\n",
    "\n",
    "def getContent(table):\n",
    "    trTag = table.select(\"tr\")[1]\n",
    "    if trTag.i: trTag.i.extract()\n",
    "    return trTag.text\n",
    "\n",
    "def getTime(table):\n",
    "    return table.select(\"td\")[1].select(\"div.authi em\")[0].text.replace(\"發表於 \",\"\").replace(\" AM\",\"\")\n",
    "\n",
    "\n",
    "######################################\n",
    "def getHiddenParams(url):\n",
    "    \n",
    "    res0  = requests.get(url)\n",
    "    soup0 = bs(res0.text,\"lxml\")\n",
    "\n",
    "    cookietime = soup0.select(\"input[name='cookietime']\")[0][\"value\"]\n",
    "    formhash   = soup0.select(\"input[name='formhash']\")[0][\"value\"]\n",
    "    # print(formhash)\n",
    "    \n",
    "    \n",
    "    return {\"cookietime\" : cookietime, \"formhash\" : formhash}\n",
    "\n",
    "######################################\n",
    "def login(formhash, cookietime):\n",
    "    \n",
    "    loginUrl = \"https://www.eyny.com/member.php?mod=logging&action=login&loginsubmit=yes&loginhash=LIhj1&inajax=1\"\n",
    "\n",
    "    payload = {\n",
    "        \"formhash\"            : formhash,\n",
    "        \"referer\"             : \"https://www.eyny.com/thread-12290829-1-GU7Y04C7.html\",\n",
    "        \"loginfield\"          : \"username\",\n",
    "        \"username\"            : \"7003un\",\n",
    "        \"password\"            : \"0939771419\",\n",
    "        \"questionid\"          : \"0\",\n",
    "        \"answer\"              : \"\",\n",
    "        \"cookietime\"          : cookietime,\n",
    "        \"g-recaptcha-response\": \"03AOLTBLSQ9n63zcqqPQQA5FCEohXZtKD76G2DoV6_HNsggOVi4BBFl7lxBDZLlCL3kyXWYbAIiRBuXN6L9e_qk1c5-R1B4noiWkEwx_IrKRP8Oshlp5N-P_J0EoikEfTMlrRjjLy59ox7PRyxoYWR9UN5cRG_5BT7iSGeeSJagwB1YZ710EbM9rqJKDrMnDzMtv9q6aL7omX0sWCu07SNZO7r81kInV8DhD7F3AMdchIZ8Y6TH-hvRUIOHnVNWG4yDo0m1TvtyUwHnDuVjq-d6sGJfSUGouoOabss2InPrhp321m79N6RUGM\"\n",
    "    }\n",
    "\n",
    "    loginHeaders = {\n",
    "        \"Host\": \"www.eyny.com\",\n",
    "        \"Origin\": \"https://www.eyny.com\",\n",
    "        \"Referer\": \"https://www.eyny.com/member.php?mod=logging&action=login\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    sess = requests.session()\n",
    "    res = sess.post(loginUrl , headers = loginHeaders , data = payload)\n",
    "    # print(res.text)\n",
    "    # print(res.cookies.get_dict())\n",
    "    \n",
    "    return sess\n",
    "######################################\n",
    "\n",
    "\n",
    "def crawlArticleList(sess):\n",
    "\n",
    "    # Step 2\n",
    "    ### 取得文章列表\n",
    "    baseUrl = \"https://www.eyny.com/\"\n",
    "    forum = \"forum-1710-1.html\"\n",
    "    links = []\n",
    "\n",
    "    headers = {\n",
    "        \"Host\": \"www.eyny.com\",\n",
    "        \"Upgrade-Insecure-Requests\": \"1\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36\"\n",
    "    }\n",
    "    res  = sess.get(baseUrl+forum , headers = headers)\n",
    "    soup = bs(res.text , \"lxml\") \n",
    "\n",
    "    subLinks = [ baseUrl+ele[\"href\"] for ele in soup.select(\"div#threadlist table[summary] th.new a.xst\")]\n",
    "    links += subLinks\n",
    "\n",
    "\n",
    "    # links\n",
    "    nextLinks = [baseUrl+a[\"href\"] for a in soup.select(\"div.pg a\")[1:10]]\n",
    "    lastLink  = baseUrl+forum\n",
    "\n",
    "    for nextLink in nextLinks:\n",
    "        headers[\"Refer\"] = lastLink\n",
    "\n",
    "        res  = s.get(nextLink , headers = headers)\n",
    "        subSoup = bs(res.text , \"lxml\") \n",
    "\n",
    "        subLinks = [ baseUrl+ele[\"href\"] for ele in subSoup.select(\"div#threadlist table[summary] th.common a.xst\")]\n",
    "        links += subLinks\n",
    "\n",
    "        lastLink = nextLink\n",
    "        \n",
    "    return links\n",
    "\n",
    "######################################\n",
    "def crawlArticleDetail(sess,links):\n",
    "\n",
    "    dataList = []\n",
    "    for l in links:\n",
    "        try:\n",
    "    #     res2  = requests.get(l,headers=headers)\n",
    "            res2  = sess.get(l,headers=headers)\n",
    "            soup2 = bs(res2.text,\"lxml\")\n",
    "            tableHeader = soup2.select(\"div#postlist > table\")[0]\n",
    "\n",
    "            pageview = tableHeader.select(\"td\")[0].select(\"span\")[1].text\n",
    "            resp_cnt = tableHeader.select(\"td\")[0].select(\"span\")[4].text\n",
    "            title    = tableHeader.select(\"td\")[1].text.replace(\"[複製鏈接]\",\"\")\n",
    "\n",
    "            tables = soup2.select(\"div#postlist > div > table\")\n",
    "            mainTable = tables[0]\n",
    "\n",
    "            author   = getAuthor(mainTable)\n",
    "            content  = getContent(mainTable)\n",
    "            time     = getTime(mainTable)\n",
    "\n",
    "            data = {\n",
    "                \"title\" : title,\n",
    "                \"time\"  : time,\n",
    "                \"content\" : content,\n",
    "                \"pageview\": pageview,\n",
    "                \"resp_cnt\": resp_cnt,\n",
    "                \"author_name\"          : author[\"author_name\"],\n",
    "                \"author_post_cnt\"      : author[\"author_post_cnt\"],\n",
    "                \"author_score\"         : author[\"author_score\"],\n",
    "                \"author_diving_value\"  : author[\"author_diving_value\"],\n",
    "                \"resp\": []\n",
    "            }\n",
    "\n",
    "            for table in tables[1:]:\n",
    "                respAuthor = getAuthor(table)\n",
    "                resp_data = {\n",
    "                    \"time\"                : getTime(table),\n",
    "                    \"content\"             : getContent(table),\n",
    "                    \"author_name\"         : respAuthor[\"author_name\"],\n",
    "                    \"author_post_cnt\"     : respAuthor[\"author_post_cnt\"],\n",
    "                    \"author_score\"        : respAuthor[\"author_score\"],\n",
    "                    \"author_diving_value\" : respAuthor[\"author_diving_value\"],\n",
    "                }\n",
    "\n",
    "                data[\"resp\"].append(resp_data)\n",
    "\n",
    "\n",
    "            dataList.append(data)\n",
    "\n",
    "            ### 檢查是否文章有效\n",
    "            print(data[\"title\"])\n",
    "            print(\"=\"*80)\n",
    "        except:\n",
    "            print(\"*\"*80)\n",
    "            traceback.print_exc()\n",
    "            print(\"*\"*80)\n",
    "            \n",
    "    return dataList\n",
    "######################################\n",
    "\n",
    "def saveFile(dataList,name):\n",
    "\n",
    "    df = pd.DataFrame(dataList)\n",
    "    df = df[[\"title\",\"time\",\"resp_cnt\",\"pageview\",\"content\",\"author_name\",\"author_post_cnt\",\"author_score\",\"author_diving_value\",\"resp\"]]\n",
    "    df.to_excel(name,index=False)\n",
    "\n",
    "    \n",
    "    \n",
    "### main    \n",
    "# Step 0\n",
    "### 取得隱藏變數\n",
    "loginPageUrl = \"https://www.eyny.com/member.php?mod=logging&action=login\"   \n",
    "hiddenParams = getHiddenParams(loginPageUrl)\n",
    "print(\"Step 0 : 取得隱藏變數 ok !!!\")\n",
    "\n",
    "\n",
    "## Step 1\n",
    "### 登入\n",
    "\n",
    "sess = login(hiddenParams[\"formhash\"], hiddenParams[\"cookietime\"])\n",
    "print(\"Step 1 : 登入 ok !!!\")\n",
    "\n",
    "\n",
    "\n",
    "# Step 2\n",
    "    ### 取得文章列表\n",
    "links = crawlArticleList(sess)    \n",
    "print(\"Step 2 : 文章列表 ok !!!\")\n",
    "\n",
    "\n",
    "\n",
    "# Step3\n",
    "### 抓取文章內容\n",
    "# l = links[8]\n",
    "\n",
    "datalist = crawlArticleDetail(sess,links[:10])\n",
    "\n",
    "print(\"Step 3 : 抓取文章內容 ok !!!\")\n",
    "\n",
    "\n",
    "# Step4\n",
    "### 存資料\n",
    "\n",
    "name= \"20190810-sample.xlsx\"\n",
    "saveFile(dataList, name)\n",
    "print(\"Step 4 : 存成 excel ok !!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title                  object\n",
      "time                   object\n",
      "resp_cnt                int32\n",
      "pageview                int32\n",
      "content                object\n",
      "author_name            object\n",
      "author_post_cnt         int64\n",
      "author_score            int64\n",
      "author_diving_value     int64\n",
      "resp                   object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "title                  object\n",
       "time                   object\n",
       "resp_cnt                int32\n",
       "pageview                int32\n",
       "content                object\n",
       "author_name            object\n",
       "author_post_cnt         int64\n",
       "author_score            int64\n",
       "author_diving_value     int64\n",
       "resp                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.dtypes)\n",
    "df = df.astype({\n",
    "    \"pageview\" : \"int32\",\n",
    "    \"author_name\" : \"str\",\n",
    "    \"resp_cnt\" : \"int32\"\n",
    "})\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'time': '2019-7-15 04:12 PM',\n",
       "  'content': '看人摟\\r\\n那就好好玩2等四吧',\n",
       "  'author_name': 'sangelva',\n",
       "  'author_post_cnt': 566,\n",
       "  'author_score': 1,\n",
       "  'author_diving_value': 12381},\n",
       " {'time': '2019-7-16 12:48',\n",
       "  'content': '只打賽季拿箱子阿~\\r\\n好像變不太出新把戲囉',\n",
       "  'author_name': 'sangelva',\n",
       "  'author_post_cnt': 566,\n",
       "  'author_score': 1,\n",
       "  'author_diving_value': 12381},\n",
       " {'time': '2019-7-16 07:04 PM',\n",
       "  'content': '2真的才是神作',\n",
       "  'author_name': 'sangelva',\n",
       "  'author_post_cnt': 566,\n",
       "  'author_score': 1,\n",
       "  'author_diving_value': 12381},\n",
       " {'time': '2019-7-17 02:12 PM',\n",
       "  'content': '唉 已經不玩很久囉 還是慢慢等4代出來再看看了 想當初剛上市時 也是各大便利商店跑 就為了買一包實體包說 ',\n",
       "  'author_name': 'sangelva',\n",
       "  'author_post_cnt': 566,\n",
       "  'author_score': 1,\n",
       "  'author_diving_value': 12381},\n",
       " {'time': '2019-7-17 02:18 PM',\n",
       "  'content': '只有新賽季會玩上半個月吧，也沒新傳奇只加個特效就要撐幾個月，內容太貧乏',\n",
       "  'author_name': 'sangelva',\n",
       "  'author_post_cnt': 566,\n",
       "  'author_score': 1,\n",
       "  'author_diving_value': 12381},\n",
       " {'time': '2019-7-17 11:42 PM',\n",
       "  'content': '老梗遊戲\\xa0 \\xa0有空就拿出來玩玩\\xa0 \\xa0當單機\\xa0 \\xa0雖然他就是有網路的單機',\n",
       "  'author_name': 'sangelva',\n",
       "  'author_post_cnt': 566,\n",
       "  'author_score': 1,\n",
       "  'author_diving_value': 12381},\n",
       " {'time': '2019-7-18 10:51',\n",
       "  'content': '我還在玩嗄!百玩不膩\\r\\n雖然沒之前那麼勤勞\\r\\n但是偶爾還是有完',\n",
       "  'author_name': 'sangelva',\n",
       "  'author_post_cnt': 566,\n",
       "  'author_score': 1,\n",
       "  'author_diving_value': 12381},\n",
       " {'time': '2019-7-19 09:05',\n",
       "  'content': ' 好久沒玩\\n\\r\\n感覺現在暴雪 搞不出新把戲了\\n\\r\\n=\"=',\n",
       "  'author_name': 'sangelva',\n",
       "  'author_post_cnt': 566,\n",
       "  'author_score': 1,\n",
       "  'author_diving_value': 12381},\n",
       " {'time': '2019-7-19 05:42 PM',\n",
       "  'content': '看最近的BZ新聞都趨向負面，D4也不用太期待了',\n",
       "  'author_name': 'sangelva',\n",
       "  'author_post_cnt': 566,\n",
       "  'author_score': 1,\n",
       "  'author_diving_value': 12381},\n",
       " {'time': '2019-7-20 01:10 PM',\n",
       "  'content': '百玩不膩的好遊戲\\r\\n不管是幾代我都想玩\\n',\n",
       "  'author_name': 'sangelva',\n",
       "  'author_post_cnt': 566,\n",
       "  'author_score': 1,\n",
       "  'author_diving_value': 12381},\n",
       " {'time': '2019-7-20 03:08 PM',\n",
       "  'content': '我也停很久了 感覺流亡好像比較有新東西可以玩',\n",
       "  'author_name': 'sangelva',\n",
       "  'author_post_cnt': 566,\n",
       "  'author_score': 1,\n",
       "  'author_diving_value': 12381},\n",
       " {'time': '2019-7-21 12:44 PM',\n",
       "  'content': '玩來玩去, 無論是畫面還是故事我還是比較喜歡2',\n",
       "  'author_name': 'sangelva',\n",
       "  'author_post_cnt': 566,\n",
       "  'author_score': 1,\n",
       "  'author_diving_value': 12381},\n",
       " {'time': '2019-7-22 12:28',\n",
       "  'content': '無聊刷刷~\\r\\n找朋友一起可能會比較持久點\\r\\n慢慢等4',\n",
       "  'author_name': 'sangelva',\n",
       "  'author_post_cnt': 566,\n",
       "  'author_score': 1,\n",
       "  'author_diving_value': 12381},\n",
       " {'time': '2019-7-24 06:11 PM',\n",
       "  'content': '剛回鍋...組了一個宏偉團...開113層...結果狂趴....果然老了....',\n",
       "  'author_name': 'sangelva',\n",
       "  'author_post_cnt': 566,\n",
       "  'author_score': 1,\n",
       "  'author_diving_value': 12381}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = df[df[\"title\"].str.contains(\"死靈\")]\n",
    "# print(data1)\n",
    "data1.count()\n",
    "\n",
    "# 2.熱門文章\n",
    "# df[df[\"pageview\"]>50000]\n",
    "\n",
    "# 3.活躍用戶 意見領袖\n",
    "data2 = df[ (df[\"author_post_cnt\"]>1016) & (df[\"author_score\"]>500)]\n",
    "data2[\"author_name\"]\n",
    "\n",
    "# print(list(data2[\"author_name\"]))\n",
    "\n",
    "# authors = {}\n",
    "\n",
    "# for a in list(data2[\"author_name\"]):\n",
    "#     if a in authors:\n",
    "#         authors[a] +=1\n",
    "#     else:\n",
    "#         authors[a] = 1 \n",
    "        \n",
    "# # print(authors)\n",
    "\n",
    "# authors\n",
    "\n",
    "# data2[data2[\"author_name\"] == \"NANABOBO2003\"]\n",
    "# groupby\n",
    "data2.groupby(\"author_name\").size()\n",
    "data2.groupby(\"author_name\").get_group(\"NANABOBO2003\")\n",
    "\n",
    "\n",
    "# 4. 各種命題\n",
    "# 1) 文章分幾類,每類個數各多少\n",
    "df.groupby(\"title\").size()\n",
    "df[\"abc\"] = 123456\n",
    "df[\"qqq\"] = df[\"author_post_cnt\"]*100\n",
    "df[\"catagory\"] = df[\"title\"].str[1:5]\n",
    "\n",
    "data3 = df.groupby(\"catagory\")\n",
    "\n",
    "# 2) 啊討論什麼\n",
    "data3.get_group(\"綜合討論\")\n",
    "\n",
    "# 3)近期主題是什麼?b\n",
    "data4 = data3.get_group(\"綜合討論\")\n",
    "\n",
    "data4[ data4[\"time\"] > \"2019-5-8\" ][3:4][\"resp\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123407\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "123407\n"
     ]
    }
   ],
   "source": [
    "# content 含有D3 or 暗黑破壞神3 的 pageview合計\n",
    "data7 = df[(df[\"title\"].str.contains(\"D3\")) | (df[\"title\"].str.contains(\"暗黑破壞神3\"))]\n",
    "print(sum(list(data7[\"pageview\"])))\n",
    "for i in list(data7[\"pageview\"]):\n",
    "    print(type(i))\n",
    "allpageview = 0\n",
    "for pageview in list(data7[\"pageview\"]):\n",
    "    allpageview+= pageview\n",
    "    \n",
    "print(allpageview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['kyo111111', 'herbert111', 'severus', 'a751106', 'andy0048', 'kkcc1103',\n",
      "       'daishan39', 'milhouse1112', 'mr0kimo', 'bbc111', 'notoriousbs', '遊人舊夢',\n",
      "       'sangelva', '寂靜之聲', 'abyss2', 'edward0606a', 'forceedge55',\n",
      "       'flytomit2017', 'eric6311', 'envy99', 'egg-11111', 'TENNOH', 'atpx2',\n",
      "       'dttvawb', 'a239211', 'a552565100', 'aa44747', 'happy760519',\n",
      "       'aa953690', 'basara30', 'jkr1428', 'hhhhh193', 'ilkid02', 'yj-climax',\n",
      "       'xxguavaxx', 'wl00089554', 'voter00000000', 's0926876620', 'raix',\n",
      "       'qwe_789963', 'papaay', 'oligokof2', 'nathan6001', 'mtf931', 'longear6',\n",
      "       'liuey', 'kkkiori', 'kaien456', '蕭神經', 'iphoneGG', '0937687494'],\n",
      "      dtype='object', name='author_name')\n",
      "[16, 4, 4, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# 時間在2018-10-01 - 2019-05-01 的作者 的文章 個數統計\n",
    "data5 = df[ (df[\"time\"] > \"2018-10-1\") & (df[\"time\"] < \"2019-5-1\")]\n",
    "data5[\"author_name\"]\n",
    "data6 = data5.groupby(\"author_name\").size().sort_values(ascending = False)\n",
    "# print(data6)\n",
    "print(data6.keys())\n",
    "print(list(data6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author_name\n",
       "HLPT             5\n",
       "Lhellraiser      1\n",
       "NANABOBO2003    15\n",
       "QWOP19840        1\n",
       "atpx2            2\n",
       "boy61012         1\n",
       "callhata         1\n",
       "cool6084         1\n",
       "fightxp          1\n",
       "jason3340        1\n",
       "jkr1428          1\n",
       "kkkiori          2\n",
       "liuey            2\n",
       "maligab          1\n",
       "mashall1         3\n",
       "nathan6001       1\n",
       "s0602002         1\n",
       "yen790914        1\n",
       "zakayara         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.groupby(\"author_name\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 10,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 17,\n",
       " 17,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 25,\n",
       " 27,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 32,\n",
       " 39,\n",
       " 49,\n",
       " 58,\n",
       " 65,\n",
       " 78,\n",
       " 78,\n",
       " 81,\n",
       " 81,\n",
       " 82,\n",
       " 82,\n",
       " 94,\n",
       " 94,\n",
       " 94,\n",
       " 94,\n",
       " 94,\n",
       " 94,\n",
       " 94,\n",
       " 94,\n",
       " 99,\n",
       " 101,\n",
       " 105,\n",
       " 108,\n",
       " 109,\n",
       " 111,\n",
       " 120,\n",
       " 120,\n",
       " 125,\n",
       " 129,\n",
       " 134,\n",
       " 136,\n",
       " 142,\n",
       " 146,\n",
       " 153,\n",
       " 153,\n",
       " 174,\n",
       " 174,\n",
       " 181,\n",
       " 183,\n",
       " 183,\n",
       " 189,\n",
       " 193,\n",
       " 194,\n",
       " 194,\n",
       " 201,\n",
       " 204,\n",
       " 204,\n",
       " 204,\n",
       " 204,\n",
       " 210,\n",
       " 210,\n",
       " 210,\n",
       " 210,\n",
       " 210,\n",
       " 210,\n",
       " 210,\n",
       " 221,\n",
       " 231,\n",
       " 241,\n",
       " 241,\n",
       " 241,\n",
       " 241,\n",
       " 241,\n",
       " 245,\n",
       " 258,\n",
       " 258,\n",
       " 262,\n",
       " 262,\n",
       " 262,\n",
       " 262,\n",
       " 262,\n",
       " 262,\n",
       " 262,\n",
       " 262,\n",
       " 262,\n",
       " 262,\n",
       " 262,\n",
       " 262,\n",
       " 262,\n",
       " 262,\n",
       " 264,\n",
       " 266,\n",
       " 273,\n",
       " 295,\n",
       " 313,\n",
       " 317,\n",
       " 334,\n",
       " 341,\n",
       " 352,\n",
       " 352,\n",
       " 369,\n",
       " 391,\n",
       " 391,\n",
       " 391,\n",
       " 391,\n",
       " 405,\n",
       " 406,\n",
       " 429,\n",
       " 433,\n",
       " 446,\n",
       " 446,\n",
       " 446,\n",
       " 446,\n",
       " 446,\n",
       " 459,\n",
       " 480,\n",
       " 506,\n",
       " 530,\n",
       " 566,\n",
       " 566,\n",
       " 566,\n",
       " 566,\n",
       " 618,\n",
       " 622,\n",
       " 636,\n",
       " 641,\n",
       " 641,\n",
       " 641,\n",
       " 669,\n",
       " 669,\n",
       " 669,\n",
       " 669,\n",
       " 669,\n",
       " 669,\n",
       " 669,\n",
       " 697,\n",
       " 726,\n",
       " 726,\n",
       " 726,\n",
       " 726,\n",
       " 726,\n",
       " 726,\n",
       " 726,\n",
       " 726,\n",
       " 726,\n",
       " 726,\n",
       " 726,\n",
       " 726,\n",
       " 726,\n",
       " 726,\n",
       " 726,\n",
       " 726,\n",
       " 726,\n",
       " 726,\n",
       " 728,\n",
       " 733,\n",
       " 793,\n",
       " 827,\n",
       " 911,\n",
       " 955,\n",
       " 1016,\n",
       " 1052,\n",
       " 1052,\n",
       " 1062,\n",
       " 1069,\n",
       " 1145,\n",
       " 1158,\n",
       " 1163,\n",
       " 1163,\n",
       " 1163,\n",
       " 1181,\n",
       " 1193,\n",
       " 1304,\n",
       " 1304,\n",
       " 1306,\n",
       " 1319,\n",
       " 1367,\n",
       " 1399,\n",
       " 1438,\n",
       " 1444,\n",
       " 1444,\n",
       " 1444,\n",
       " 1877,\n",
       " 1877,\n",
       " 1983,\n",
       " 2091,\n",
       " 2213,\n",
       " 2300,\n",
       " 2446,\n",
       " 2536,\n",
       " 2536,\n",
       " 2536,\n",
       " 2536,\n",
       " 2536,\n",
       " 2536,\n",
       " 2536,\n",
       " 2536,\n",
       " 2536,\n",
       " 2536,\n",
       " 2536,\n",
       " 2536,\n",
       " 2536,\n",
       " 2536,\n",
       " 2536,\n",
       " 2629,\n",
       " 2629,\n",
       " 3581,\n",
       " 4195,\n",
       " 4195,\n",
       " 4450,\n",
       " 4450,\n",
       " 4450,\n",
       " 4450,\n",
       " 4450]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(df[\"author_post_cnt\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
